{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d896481-ccf7-4fcf-8999-0192b9fad7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Основные библиотеки\n",
    "# ==========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# ==========================\n",
    "# Визуализация\n",
    "# ==========================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================\n",
    "# Предобработка данных\n",
    "# ==========================\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# ==========================\n",
    "# Модели и обучение\n",
    "# ==========================\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor,\n",
    "    StackingRegressor, AdaBoostRegressor\n",
    ")\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# ==========================\n",
    "# Метрики\n",
    "# ==========================\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
    ")\n",
    "\n",
    "# ==========================\n",
    "# Библиотеки для бустинга\n",
    "# ==========================\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "# ==========================\n",
    "# Статистика\n",
    "# ==========================\n",
    "from scipy.stats import f_oneway\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86e105e4-a5fc-4702-bb48-06e87c0c6b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df.csv\")\n",
    "df_bin = pd.read_csv(\"df_bin.csv\")\n",
    "df_cut = pd.read_csv(\"df_cut.csv\")\n",
    "df_cut_bin = pd.read_csv(\"df_cut_bin.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5192935f-e231-4dcb-8a8f-80005019329c",
   "metadata": {},
   "source": [
    "огрешности двух моделей складываются при вычислении разности\n",
    "\n",
    "При вычитании предсказаний двух моделей ошибки могут усиливаться и приводить к сильному ухудшению качества.\n",
    "\n",
    "Сильная корреляция IC50 и CC50?\n",
    "\n",
    "Если IC50 и CC50 в данных коррелируют, но модели обучены отдельно, то простое вычитание может не давать точного результата для SI.\n",
    "\n",
    "Погрешности в данных\n",
    "\n",
    "Если в данных есть шум или выбросы, они влияют сильнее при вычислении разности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b2ec94-e0e7-46d8-9f57-d74f258798a7",
   "metadata": {},
   "source": [
    "Сравниваем разные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "615f916d-b704-4a18-a921-842714690a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\apex_\\anaconda3\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in c:\\users\\apex_\\anaconda3\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\apex_\\anaconda3\\lib\\site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in c:\\users\\apex_\\anaconda3\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\apex_\\anaconda3\\lib\\site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\apex_\\anaconda3\\lib\\site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\apex_\\anaconda3\\lib\\site-packages (from catboost) (6.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\apex_\\appdata\\roaming\\python\\python312\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\apex_\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\apex_\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\apex_\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\apex_\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\apex_\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\apex_\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\apex_\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\apex_\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\apex_\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\apex_\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\apex_\\anaconda3\\lib\\site-packages (from plotly->catboost) (1.36.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c38014fa-8b2e-4eb1-8a90-06289ae1636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['IC50, mM'])\n",
    "df_bin = df_bin.drop(columns=['IC50, mM'])\n",
    "df_cut = df_cut.drop(columns=['IC50, mM'])\n",
    "df_cut_bin = df_cut_bin.drop(columns=['IC50, mM'])\n",
    "df = df.drop(columns=['SI'])\n",
    "df_bin = df_bin.drop(columns=['SI'])\n",
    "df_cut = df_cut.drop(columns=['SI'])\n",
    "df_cut_bin = df_cut_bin.drop(columns=['SI'])\n",
    "df = df.drop(columns=['log_IC50'])\n",
    "df_bin = df_bin.drop(columns=['log_IC50'])\n",
    "df_cut = df_cut.drop(columns=['log_IC50'])\n",
    "df_cut_bin = df_cut_bin.drop(columns=['log_IC50'])\n",
    "df = df.drop(columns=['log_CC50'])\n",
    "df_bin = df_bin.drop(columns=['log_CC50'])\n",
    "df_cut = df_cut.drop(columns=['log_CC50'])\n",
    "df_cut_bin = df_cut_bin.drop(columns=['log_CC50'])\n",
    "df = df.drop(columns=['CC50, mM'])\n",
    "df_bin = df_bin.drop(columns=['CC50, mM'])\n",
    "df_cut = df_cut.drop(columns=['CC50, mM'])\n",
    "df_cut_bin = df_cut_bin.drop(columns=['CC50, mM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f67848-89b4-465a-9305-4f8d19bb7525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation on df ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation (228 features):  11%|█         | 1/9 [00:03<00:30,  3.76s/it]"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Очистка имён колонок и замена inf на nan\n",
    "for d in [df, df_cut, df_bin, df_cut_bin]:\n",
    "    d.columns = d.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "    d.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestRegressor(random_state=42)),\n",
    "    ('xgb', XGBRegressor(random_state=42, verbosity=0)),\n",
    "    ('gb', GradientBoostingRegressor(random_state=42)),\n",
    "    ('cat', CatBoostRegressor(verbose=0, random_state=42)),\n",
    "]\n",
    "\n",
    "final_estimator = LinearRegression()\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=final_estimator,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"KNN\": KNeighborsRegressor(),\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"HistGradientBoosting\": HistGradientBoostingRegressor(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostRegressor(random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42, verbosity=0),\n",
    "    \"LightGBM\": LGBMRegressor(random_state=42, min_gain_to_split=0, max_depth=6, num_leaves=31, verbose=-1),\n",
    "    \"CatBoost\": CatBoostRegressor(\n",
    "        verbose=0,\n",
    "        random_state=42,\n",
    "        bagging_temperature=0,\n",
    "        depth=5,\n",
    "        iterations=300,\n",
    "        l2_leaf_reg=3,\n",
    "        learning_rate=0.05\n",
    "    ),\n",
    "    \"Stacking\": stacking_model\n",
    "}\n",
    "\n",
    "\n",
    "def evaluate_models(df_input, y_col='log_SI'):\n",
    "    df_eval = df_input.copy()\n",
    "    df_eval = df_eval.drop(columns=['Unnamed_0'], errors='ignore')\n",
    "\n",
    "    X = df_eval.drop(columns=[y_col])\n",
    "    y = df_eval[y_col]\n",
    "\n",
    "    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed), columns=X.columns)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = []\n",
    "\n",
    "    for name, model in tqdm(models.items(), desc=f\"Cross-validation ({df_input.shape[1]} features)\"):\n",
    "        try:\n",
    "            cv_results = cross_validate(\n",
    "                model, X_scaled, y,\n",
    "                cv=kf,\n",
    "                scoring=['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2', 'neg_median_absolute_error'],\n",
    "                return_train_score=False,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "\n",
    "            mae_mean = -np.mean(cv_results['test_neg_mean_absolute_error'])\n",
    "            mse_mean = -np.mean(cv_results['test_neg_mean_squared_error'])\n",
    "            rmse_mean = np.sqrt(mse_mean)\n",
    "            r2_mean = np.mean(cv_results['test_r2'])\n",
    "            medae_mean = -np.mean(cv_results['test_neg_median_absolute_error'])\n",
    "\n",
    "            results.append({\n",
    "                \"Model\": name,\n",
    "                \"MAE\": mae_mean,\n",
    "                \"MSE\": mse_mean,\n",
    "                \"RMSE\": rmse_mean,\n",
    "                \"MedAE\": medae_mean,\n",
    "                \"R²\": r2_mean\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error in model {name}: {e}\")\n",
    "    return pd.DataFrame(results).sort_values(by=\"RMSE\"), X_scaled, y, imputer, scaler\n",
    "\n",
    "# Оценка всех датасетов и сбор результатов\n",
    "print(\"=== Evaluation on df ===\")\n",
    "results_df, X_df_scaled, y_df, imputer_df, scaler_df = evaluate_models(df)\n",
    "results_df['Dataset'] = 'df'\n",
    "\n",
    "print(\"=== Evaluation on df_cut ===\")\n",
    "results_df_cut, X_cut_scaled, y_cut, imputer_cut, scaler_cut = evaluate_models(df_cut)\n",
    "results_df_cut['Dataset'] = 'df_cut'\n",
    "\n",
    "print(\"=== Evaluation on df_bin ===\")\n",
    "results_df_bin, X_bin_scaled, y_bin, imputer_bin, scaler_bin = evaluate_models(df_bin)\n",
    "results_df_bin['Dataset'] = 'df_bin'\n",
    "\n",
    "print(\"=== Evaluation on df_cut_bin ===\")\n",
    "results_df_cut_bin, X_cut_bin_scaled, y_cut_bin, imputer_cut_bin, scaler_cut_bin = evaluate_models(df_cut_bin)\n",
    "results_df_cut_bin['Dataset'] = 'df_cut_bin'\n",
    "\n",
    "comparison_df = pd.concat([results_df, results_df_cut, results_df_bin, results_df_cut_bin], ignore_index=True)\n",
    "\n",
    "# Визуализация RMSE\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.barplot(data=comparison_df, x='RMSE', y='Model', hue='Dataset', palette='Set2')\n",
    "plt.title(\"Model RMSE Comparison Across Datasets\")\n",
    "plt.xlabel(\"RMSE\")\n",
    "plt.ylabel(\"Model\")\n",
    "plt.legend(title=\"Dataset\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Визуализация R²\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.barplot(data=comparison_df, x='R²', y='Model', hue='Dataset', palette='Set1')\n",
    "plt.title(\"Model R² Comparison Across Datasets\")\n",
    "plt.xlabel(\"R²\")\n",
    "plt.ylabel(\"Model\")\n",
    "plt.legend(title=\"Dataset\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nModel metrics comparison:\")\n",
    "print(comparison_df.pivot_table(index=\"Model\", columns=\"Dataset\", values=[\"RMSE\", \"R²\", \"MAE\"]).round(4))\n",
    "\n",
    "# --- Визуализация важности признаков для CatBoost на df (пример) ---\n",
    "cat_model = models['CatBoost']\n",
    "cat_model.fit(X_df_scaled, y_df)\n",
    "\n",
    "# Получение важности признаков\n",
    "feature_importances = cat_model.get_feature_importance(Pool(X_df_scaled, label=y_df))\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    'Feature': X_df_scaled.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feat_imp_df.head(20))\n",
    "plt.title(\"Top 20 Feature Importances - CatBoost (df)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- График остатков для лучшей модели на df ---\n",
    "# Определим лучшую модель по RMSE на df\n",
    "best_model_name = results_df.loc[results_df['RMSE'].idxmin(), 'Model']\n",
    "print(f\"Best model on df by RMSE: {best_model_name}\")\n",
    "\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Для графика остатков нужна обучающая и тестовая выборка\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df_scaled, y_df, test_size=0.2, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_pred, y=residuals)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals (Actual - Predicted)')\n",
    "plt.title(f'Residuals plot for best model: {best_model_name}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Сохраняем результаты в Excel и PDF ---\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "with PdfPages('regression_evaluation_report_SI.pdf') as pdf:\n",
    "    # RMSE Plot\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.barplot(data=comparison_df, x='RMSE', y='Model', hue='Dataset', palette='Set2')\n",
    "    plt.title(\"Model RMSE Comparison Across Datasets\")\n",
    "    plt.xlabel(\"RMSE\")\n",
    "    plt.ylabel(\"Model\")\n",
    "    plt.legend(title=\"Dataset\")\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # R² Plot\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.barplot(data=comparison_df, x='R²', y='Model', hue='Dataset', palette='Set1')\n",
    "    plt.title(\"Model R² Comparison Across Datasets\")\n",
    "    plt.xlabel(\"R²\")\n",
    "    plt.ylabel(\"Model\")\n",
    "    plt.legend(title=\"Dataset\")\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # Feature importance CatBoost\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feat_imp_df.head(20))\n",
    "    plt.title(\"Top 20 Feature Importances - CatBoost (df)\")\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # Residuals plot best model\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=y_pred, y=residuals)\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.xlabel('Predicted values')\n",
    "    plt.ylabel('Residuals (Actual - Predicted)')\n",
    "    plt.title(f'Residuals plot for best model: {best_model_name}')\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # Табличное сравнение\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    table_data = comparison_df.pivot_table(\n",
    "        index=\"Model\",\n",
    "        columns=\"Dataset\",\n",
    "        values=[\"RMSE\", \"R²\", \"MAE\"]\n",
    "    ).round(4)\n",
    "\n",
    "    tbl = ax.table(\n",
    "        cellText=table_data.values,\n",
    "        colLabels=[f'{metric}_{ds}' for metric, ds in table_data.columns],\n",
    "        rowLabels=table_data.index,\n",
    "        loc='center',\n",
    "        cellLoc='center'\n",
    "    )\n",
    "    tbl.auto_set_font_size(False)\n",
    "    tbl.set_fontsize(10)\n",
    "    tbl.scale(1.2, 1.2)\n",
    "    ax.set_title(\"Model metrics comparison\")\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "with pd.ExcelWriter(\"regression_comparison_metrics_SI.xlsx\") as writer:\n",
    "    results_df.to_excel(writer, sheet_name=\"df\", index=False)\n",
    "    results_df_cut.to_excel(writer, sheet_name=\"df_cut\", index=False)\n",
    "    results_df_bin.to_excel(writer, sheet_name=\"df_bin\", index=False)\n",
    "    results_df_cut_bin.to_excel(writer, sheet_name=\"df_cut_bin\", index=False)\n",
    "    comparison_df.to_excel(writer, sheet_name=\"Comparison\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "723b97fb-9be4-40db-84cd-76d97f138742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдены колонки, содержащие 'SI':\n",
      "- log_SI\n"
     ]
    }
   ],
   "source": [
    "si_columns = [col for col in df_bin.columns if 'SI' in col]\n",
    "\n",
    "if si_columns:\n",
    "    print(\"Найдены колонки, содержащие 'SI':\")\n",
    "    for col in si_columns:\n",
    "        print(f\"- {col}\")\n",
    "else:\n",
    "    print(\"Колонки, содержащие 'SI', не найдены.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7771376b-6f60-4b3d-8bc0-0f135264d053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Признаки log_IC50 и log_CC50 добавлены в df_bin.\n",
      "Running 6-fold cross-validation...\n",
      "Fold 1 R²: 0.4905\n",
      "Fold 2 R²: 0.5167\n",
      "Fold 3 R²: 0.5772\n",
      "Fold 4 R²: 0.5689\n",
      "Fold 5 R²: 0.5844\n",
      "Fold 6 R²: 0.5413\n",
      "\n",
      "Cross-validation results:\n",
      "MAE: 0.3366 ± 0.0153\n",
      "RMSE: 0.5032 ± 0.0300\n",
      "R²: 0.5465 ± 0.0340\n",
      "\n",
      "Test set performance:\n",
      "MAE: 0.3581\n",
      "MSE: 0.2963\n",
      "RMSE: 0.5443\n",
      "MedAE: 0.2375\n",
      "R²: 0.5052\n",
      "\n",
      "Top 30 важнейших признаков:\n",
      "S_2: 34.2444\n",
      "log_2: 27.4106\n",
      "log_IC50: 8.9237\n",
      "log_CC50: 1.5336\n",
      "VSA_EState8: 1.2799\n",
      "PEOE_VSA9: 0.8182\n",
      "FpDensityMorgan3: 0.6371\n",
      "SlogP_VSA5: 0.5134\n",
      "EState_VSA3: 0.4939\n",
      "EState_VSA4: 0.4870\n",
      "VSA_EState6: 0.4391\n",
      "EState_VSA7: 0.4262\n",
      "MinAbsEStateIndex: 0.4186\n",
      "VSA_EState7: 0.4085\n",
      "qed: 0.4048\n",
      "EState_VSA2: 0.3847\n",
      "VSA_EState3: 0.3834\n",
      "AvgIpc: 0.3825\n",
      "PEOE_VSA7: 0.3781\n",
      "EState_VSA8: 0.3722\n",
      "BCUT2D_MRLOW: 0.3698\n",
      "FpDensityMorgan1: 0.3594\n",
      "VSA_EState1: 0.3569\n",
      "MolWt_TPSA_ratio: 0.3529\n",
      "Chi_std: 0.3445\n",
      "EState_VSA_std: 0.3412\n",
      "Log_Flexibility: 0.3363\n",
      "BCUT2D_MRHI: 0.3273\n",
      "VSA_EState4: 0.3157\n",
      "SMR_VSA_max: 0.3056\n",
      "Финальная модель обучена на всех данных и сохранена в 'catboost_final_model_SI.pkl'\n",
      "Графики сохранены в 'log(SI) catboost_residuals_plot.png' и 'log(SI) catboost_feature_importance_top30.png'\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import joblib\n",
    "\n",
    "# === Подготовка данных ===\n",
    "# df_bin уже должен быть загружен на этом этапе\n",
    "\n",
    "# === Добавление признака log_IC50 ===\n",
    "ic50_model = joblib.load('regression_IC50_catboost_final_model_bin.pkl')\n",
    "\n",
    "X_ic50 = df_bin.copy()\n",
    "X_ic50.columns = X_ic50.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "X_ic50.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "if 'log_IC50' in X_ic50.columns:\n",
    "    X_ic50.drop(columns=['log_IC50'], inplace=True)\n",
    "\n",
    "ic50_imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_ic50_imputed = pd.DataFrame(ic50_imputer.fit_transform(X_ic50), columns=X_ic50.columns)\n",
    "\n",
    "df_bin['log_IC50'] = ic50_model.predict(X_ic50_imputed)\n",
    "\n",
    "# === Добавление признака log_CC50 ===\n",
    "cc50_model = joblib.load('regression_CC50_lightgbm_final_model_bin.pkl')\n",
    "\n",
    "X_cc50 = df_bin.copy()\n",
    "X_cc50.columns = X_cc50.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "X_cc50.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Удаляем признаки, которых не было при обучении CC50 модели\n",
    "for col_to_drop in ['log_IC50', 'log_CC50', 'log_SI']:\n",
    "    if col_to_drop in X_cc50.columns:\n",
    "        X_cc50.drop(columns=[col_to_drop], inplace=True)\n",
    "\n",
    "cc50_imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_cc50_imputed = pd.DataFrame(cc50_imputer.fit_transform(X_cc50), columns=X_cc50.columns)\n",
    "\n",
    "df_bin['log_CC50'] = cc50_model.predict(X_cc50_imputed)\n",
    "\n",
    "df_bin['log_2'] = df_bin['log_IC50'] - df_bin['log_CC50']\n",
    "\n",
    "df_bin['S_2'] = 10**df_bin['log_2']\n",
    "\n",
    "print(\"Признаки log_IC50 и log_CC50 добавлены в df_bin.\")\n",
    "\n",
    "# === Обучение модели для log_SI ===\n",
    "df_copy = df_bin.copy()\n",
    "df_copy.columns = df_copy.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "df_copy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "if 'Unnamed_0' in df_copy.columns:\n",
    "    df_copy.drop(columns=['Unnamed_0'], inplace=True)\n",
    "\n",
    "X = df_copy.drop(columns=['log_SI'])\n",
    "y = df_copy['log_SI']\n",
    "\n",
    "# Импутация\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Параметры CatBoost\n",
    "catboost_params = {\n",
    "    'bagging_temperature': 0.13,\n",
    "    'depth': 5,\n",
    "    'iterations': 626,\n",
    "    'l2_leaf_reg': 4.2,\n",
    "    'learning_rate': 0.04,\n",
    "    'verbose': 0,\n",
    "    'random_state': 42,\n",
    "    'loss_function': 'RMSE'\n",
    "}\n",
    "\n",
    "# Кросс-валидация\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "mae_list, mse_list, rmse_list, medae_list, r2_list = [], [], [], [], []\n",
    "\n",
    "print(\"Running 6-fold cross-validation...\")\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_imputed), 1):\n",
    "    X_train_cv, X_val_cv = X_imputed.iloc[train_index], X_imputed.iloc[val_index]\n",
    "    y_train_cv, y_val_cv = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model_cv = CatBoostRegressor(**catboost_params)\n",
    "    model_cv.fit(X_train_cv, y_train_cv, verbose=0)\n",
    "\n",
    "    y_pred_cv = model_cv.predict(X_val_cv)\n",
    "\n",
    "    mae_list.append(mean_absolute_error(y_val_cv, y_pred_cv))\n",
    "    mse_list.append(mean_squared_error(y_val_cv, y_pred_cv))\n",
    "    rmse_list.append(np.sqrt(mse_list[-1]))\n",
    "    medae_list.append(median_absolute_error(y_val_cv, y_pred_cv))\n",
    "    r2_list.append(r2_score(y_val_cv, y_pred_cv))\n",
    "\n",
    "    print(f\"Fold {fold} R²: {r2_list[-1]:.4f}\")\n",
    "\n",
    "print(\"\\nCross-validation results:\")\n",
    "print(f\"MAE: {np.mean(mae_list):.4f} ± {np.std(mae_list):.4f}\")\n",
    "print(f\"RMSE: {np.mean(rmse_list):.4f} ± {np.std(rmse_list):.4f}\")\n",
    "print(f\"R²: {np.mean(r2_list):.4f} ± {np.std(r2_list):.4f}\")\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.25, random_state=42)\n",
    "\n",
    "cat_model_eval = CatBoostRegressor(**catboost_params)\n",
    "cat_model_eval.fit(X_train, y_train)\n",
    "\n",
    "y_pred = cat_model_eval.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nTest set performance:\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MedAE: {medae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "# График остатков\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_pred, y=residuals)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals (Actual - Predicted)')\n",
    "plt.title(f'log(SI): Residuals plot - CatBoost evaluation model (Test set R²={r2:.4f})')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"log(SI) catboost_residuals_plot.png\")\n",
    "plt.close()\n",
    "\n",
    "# Важность признаков\n",
    "cat_model_final = CatBoostRegressor(**catboost_params)\n",
    "cat_model_final.fit(X_imputed, y)\n",
    "\n",
    "feature_importances = cat_model_final.get_feature_importance(Pool(X_imputed, label=y))\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    'Feature': X_imputed.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 30 важнейших признаков:\")\n",
    "for i, row in feat_imp_df.head(30).iterrows():\n",
    "    print(f\"{row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "sns.barplot(x='Importance', y='Feature', data=feat_imp_df.head(30))\n",
    "plt.title(\"log(SI): Top 30 Feature Importances CatBoost Final Model\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"log(SI) catboost_feature_importance_top30.png\")\n",
    "plt.close()\n",
    "\n",
    "# Сохранение модели\n",
    "joblib.dump(cat_model_final, 'catboost_final_model_SI.pkl')\n",
    "print(\"Финальная модель обучена на всех данных и сохранена в 'catboost_final_model_SI.pkl'\")\n",
    "print(\"Графики сохранены в 'log(SI) catboost_residuals_plot.png' и 'log(SI) catboost_feature_importance_top30.png'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a7e20f-4ae1-4e1c-8c67-f341400910c9",
   "metadata": {},
   "source": [
    "- по важным признакам только"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ca07610d-f572-45ed-acd5-00949dec70f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Признаки log_IC50 и log_CC50 добавлены в df_bin.\n",
      "Используем топ-50 признаков по важности для обучения модели:\n",
      "- S_2\n",
      "- log_2\n",
      "- log_IC50\n",
      "- log_CC50\n",
      "- VSA_EState8\n",
      "- PEOE_VSA9\n",
      "- FpDensityMorgan3\n",
      "- SlogP_VSA5\n",
      "- EState_VSA3\n",
      "- EState_VSA4\n",
      "- VSA_EState6\n",
      "\n",
      "Running 6-fold cross-validation on top-50 features...\n",
      "Fold 1 R²: 0.4976\n",
      "Fold 2 R²: 0.5242\n",
      "Fold 3 R²: 0.5947\n",
      "Fold 4 R²: 0.5888\n",
      "Fold 5 R²: 0.6010\n",
      "Fold 6 R²: 0.5648\n",
      "\n",
      "Cross-validation results (top-50 features):\n",
      "MAE: 0.3294 ± 0.0202\n",
      "RMSE: 0.4945 ± 0.0317\n",
      "R²: 0.5618 ± 0.0385\n",
      "\n",
      "Test set performance (top-50 features):\n",
      "MAE: 0.3494\n",
      "MSE: 0.2788\n",
      "RMSE: 0.5280\n",
      "MedAE: 0.2318\n",
      "R²: 0.5344\n",
      "\n",
      "Top 30 важнейших признаков финальной модели:\n",
      "             Feature  Importance\n",
      "0                S_2   31.241017\n",
      "1              log_2   29.671547\n",
      "2           log_IC50   11.835889\n",
      "3           log_CC50    4.979729\n",
      "4        VSA_EState8    4.753341\n",
      "5          PEOE_VSA9    3.838632\n",
      "6   FpDensityMorgan3    3.292648\n",
      "10       VSA_EState6    2.956686\n",
      "8        EState_VSA3    2.782749\n",
      "9        EState_VSA4    2.711554\n",
      "7         SlogP_VSA5    1.936210\n",
      "Финальная модель обучена на топ-50 признаках и сохранена в 'catboost_final_model_SI_top50.pkl'\n",
      "Графики сохранены с суффиксом '_top50'.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import joblib\n",
    "\n",
    "# === Подготовка данных ===\n",
    "# df_bin уже должен быть загружен\n",
    "\n",
    "# === Добавление признаков log_IC50, log_CC50 и расчет log_2, S_2 ===\n",
    "ic50_model = joblib.load('regression_IC50_catboost_final_model_bin.pkl')\n",
    "cc50_model = joblib.load('regression_CC50_lightgbm_final_model_bin.pkl')\n",
    "\n",
    "def add_predicted_feature(df, model, drop_cols=None, imputer_strategy='most_frequent'):\n",
    "    df_tmp = df.copy()\n",
    "    df_tmp.columns = df_tmp.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "    df_tmp.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    if drop_cols:\n",
    "        for c in drop_cols:\n",
    "            if c in df_tmp.columns:\n",
    "                df_tmp.drop(columns=[c], inplace=True)\n",
    "    imputer = SimpleImputer(strategy=imputer_strategy)\n",
    "    X_imputed = pd.DataFrame(imputer.fit_transform(df_tmp), columns=df_tmp.columns)\n",
    "    preds = model.predict(X_imputed)\n",
    "    return preds\n",
    "\n",
    "df_bin['log_IC50'] = add_predicted_feature(df_bin, ic50_model, drop_cols=['log_IC50'])\n",
    "df_bin['log_CC50'] = add_predicted_feature(df_bin, cc50_model, drop_cols=['log_IC50', 'log_CC50', 'log_SI'])\n",
    "df_bin['log_2'] = df_bin['log_IC50'] - df_bin['log_CC50']\n",
    "df_bin['S_2'] = 10**df_bin['log_2']\n",
    "\n",
    "print(\"Признаки log_IC50 и log_CC50 добавлены в df_bin.\")\n",
    "\n",
    "# === Подготовка датасета для log_SI ===\n",
    "df_copy = df_bin.copy()\n",
    "df_copy.columns = df_copy.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "df_copy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "if 'Unnamed_0' in df_copy.columns:\n",
    "    df_copy.drop(columns=['Unnamed_0'], inplace=True)\n",
    "\n",
    "X = df_copy.drop(columns=['log_SI'])\n",
    "y = df_copy['log_SI']\n",
    "\n",
    "# Импутация\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Параметры CatBoost\n",
    "catboost_params = {\n",
    "    'bagging_temperature': 0.13,\n",
    "    'depth': 5,\n",
    "    'iterations': 626,\n",
    "    'l2_leaf_reg': 4.2,\n",
    "    'learning_rate': 0.04,\n",
    "    'verbose': 0,\n",
    "    'random_state': 42,\n",
    "    'loss_function': 'RMSE'\n",
    "}\n",
    "\n",
    "# Обучаем модель на всех признаках, чтобы получить важность\n",
    "model_full = CatBoostRegressor(**catboost_params)\n",
    "model_full.fit(X_imputed, y)\n",
    "\n",
    "feature_importances = model_full.get_feature_importance(Pool(X_imputed, label=y))\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    'Feature': X_imputed.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Выбираем топ-50 признаков\n",
    "top_50_features = feat_imp_df.head(11)['Feature'].tolist()\n",
    "print(f\"Используем топ-50 признаков по важности для обучения модели:\")\n",
    "\n",
    "for f in top_50_features:\n",
    "    print(f\"- {f}\")\n",
    "\n",
    "# Отбираем только топ-50 признаков\n",
    "X_top50 = X_imputed[top_50_features]\n",
    "\n",
    "# Кросс-валидация на топ-50 признаках\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "mae_list, mse_list, rmse_list, medae_list, r2_list = [], [], [], [], []\n",
    "\n",
    "print(\"\\nRunning 6-fold cross-validation on top-50 features...\")\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_top50), 1):\n",
    "    X_train_cv, X_val_cv = X_top50.iloc[train_index], X_top50.iloc[val_index]\n",
    "    y_train_cv, y_val_cv = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model_cv = CatBoostRegressor(**catboost_params)\n",
    "    model_cv.fit(X_train_cv, y_train_cv, verbose=0)\n",
    "\n",
    "    y_pred_cv = model_cv.predict(X_val_cv)\n",
    "\n",
    "    mae_list.append(mean_absolute_error(y_val_cv, y_pred_cv))\n",
    "    mse_list.append(mean_squared_error(y_val_cv, y_pred_cv))\n",
    "    rmse_list.append(np.sqrt(mse_list[-1]))\n",
    "    medae_list.append(median_absolute_error(y_val_cv, y_pred_cv))\n",
    "    r2_list.append(r2_score(y_val_cv, y_pred_cv))\n",
    "\n",
    "    print(f\"Fold {fold} R²: {r2_list[-1]:.4f}\")\n",
    "\n",
    "print(\"\\nCross-validation results (top-50 features):\")\n",
    "print(f\"MAE: {np.mean(mae_list):.4f} ± {np.std(mae_list):.4f}\")\n",
    "print(f\"RMSE: {np.mean(rmse_list):.4f} ± {np.std(rmse_list):.4f}\")\n",
    "print(f\"R²: {np.mean(r2_list):.4f} ± {np.std(r2_list):.4f}\")\n",
    "\n",
    "# Разделение на train/test с топ-50 признаками\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top50, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Обучение модели на train с топ-50 признаками\n",
    "cat_model_eval = CatBoostRegressor(**catboost_params)\n",
    "cat_model_eval.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания и оценка на тесте\n",
    "y_pred = cat_model_eval.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nTest set performance (top-50 features):\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MedAE: {medae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "# График остатков\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_pred, y=residuals)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals (Actual - Predicted)')\n",
    "plt.title(f'log(SI): Residuals plot - CatBoost evaluation model (Test set R²={r2:.4f})')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"log(SI)_catboost_residuals_plot_top50.png\")\n",
    "plt.close()\n",
    "\n",
    "# Финальная модель на всех данных с топ-50 признаками\n",
    "cat_model_final = CatBoostRegressor(**catboost_params)\n",
    "cat_model_final.fit(X_top50, y)\n",
    "\n",
    "feature_importances_final = cat_model_final.get_feature_importance(Pool(X_top50, label=y))\n",
    "feat_imp_df_final = pd.DataFrame({\n",
    "    'Feature': X_top50.columns,\n",
    "    'Importance': feature_importances_final\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 30 важнейших признаков финальной модели:\")\n",
    "print(feat_imp_df_final.head(30))\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "sns.barplot(x='Importance', y='Feature', data=feat_imp_df_final.head(30))\n",
    "plt.title(\"log(SI): Top 30 Feature Importances CatBoost Final Model (top-50 features)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"log(SI)_catboost_feature_importance_top30_top50.png\")\n",
    "plt.close()\n",
    "\n",
    "# Сохраняем финальную модель\n",
    "joblib.dump(cat_model_final, 'catboost_final_model_SI_top50.pkl')\n",
    "print(\"Финальная модель обучена на топ-50 признаках и сохранена в 'catboost_final_model_SI_top50.pkl'\")\n",
    "print(\"Графики сохранены с суффиксом '_top50'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4878a123-f630-4aee-900f-7084af6ba80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Признаки log_IC50 и log_CC50 добавлены в df_bin.\n",
      "Используем топ-50 признаков по важности для обучения модели:\n",
      "- log_2\n",
      "- S_2\n",
      "- log_IC50\n",
      "- log_CC50\n",
      "- MolLogP\n",
      "- VSA_EState4\n",
      "- FpDensityMorgan1\n",
      "- EState_VSA_std\n",
      "- FpDensityMorgan2\n",
      "- EState_VSA4\n",
      "- BCUT2D_MRLOW\n",
      "\n",
      "Running 6-fold cross-validation on top-50 features...\n",
      "Fold 1 R²: 0.4648\n",
      "Fold 2 R²: 0.5179\n",
      "Fold 3 R²: 0.5497\n",
      "Fold 4 R²: 0.5416\n",
      "Fold 5 R²: 0.5918\n",
      "Fold 6 R²: 0.5056\n",
      "\n",
      "Cross-validation results (top-50 features):\n",
      "MAE: 0.3471 ± 0.0188\n",
      "RMSE: 0.5131 ± 0.0334\n",
      "R²: 0.5286 ± 0.0394\n",
      "\n",
      "Test set performance (top-50 features):\n",
      "MAE: 0.3543\n",
      "MSE: 0.2892\n",
      "RMSE: 0.5378\n",
      "MedAE: 0.2306\n",
      "R²: 0.5171\n",
      "\n",
      "Top 30 важнейших признаков финальной модели:\n",
      "             Feature  Importance\n",
      "1                S_2    0.398206\n",
      "0              log_2    0.385436\n",
      "2           log_IC50    0.041064\n",
      "3           log_CC50    0.028586\n",
      "5        VSA_EState4    0.025041\n",
      "4            MolLogP    0.024379\n",
      "7     EState_VSA_std    0.020963\n",
      "9        EState_VSA4    0.019664\n",
      "10      BCUT2D_MRLOW    0.019648\n",
      "8   FpDensityMorgan2    0.019162\n",
      "6   FpDensityMorgan1    0.017852\n",
      "Финальная модель обучена на топ-50 признаках и сохранена в 'rf_final_model_SI_top50.pkl'\n",
      "Графики сохранены с суффиксом '_top50'.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "# === Подготовка данных ===\n",
    "# df_bin уже должен быть загружен\n",
    "\n",
    "# === Добавление признаков log_IC50, log_CC50 и расчет log_2, S_2 ===\n",
    "ic50_model = joblib.load('regression_IC50_catboost_final_model_bin.pkl')\n",
    "cc50_model = joblib.load('regression_CC50_lightgbm_final_model_bin.pkl')\n",
    "\n",
    "def add_predicted_feature(df, model, drop_cols=None, imputer_strategy='most_frequent'):\n",
    "    df_tmp = df.copy()\n",
    "    df_tmp.columns = df_tmp.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "    df_tmp.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    if drop_cols:\n",
    "        for c in drop_cols:\n",
    "            if c in df_tmp.columns:\n",
    "                df_tmp.drop(columns=[c], inplace=True)\n",
    "    imputer = SimpleImputer(strategy=imputer_strategy)\n",
    "    X_imputed = pd.DataFrame(imputer.fit_transform(df_tmp), columns=df_tmp.columns)\n",
    "    preds = model.predict(X_imputed)\n",
    "    return preds\n",
    "\n",
    "df_bin['log_IC50'] = add_predicted_feature(df_bin, ic50_model, drop_cols=['log_IC50'])\n",
    "df_bin['log_CC50'] = add_predicted_feature(df_bin, cc50_model, drop_cols=['log_IC50', 'log_CC50', 'log_SI'])\n",
    "df_bin['log_2'] = df_bin['log_IC50'] - df_bin['log_CC50']\n",
    "df_bin['S_2'] = 10**df_bin['log_2']\n",
    "\n",
    "print(\"Признаки log_IC50 и log_CC50 добавлены в df_bin.\")\n",
    "\n",
    "# === Подготовка датасета для log_SI ===\n",
    "df_copy = df_bin.copy()\n",
    "df_copy.columns = df_copy.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "df_copy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "if 'Unnamed_0' in df_copy.columns:\n",
    "    df_copy.drop(columns=['Unnamed_0'], inplace=True)\n",
    "\n",
    "X = df_copy.drop(columns=['log_SI'])\n",
    "y = df_copy['log_SI']\n",
    "\n",
    "# Импутация\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Параметры RandomForest\n",
    "rf_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': None,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Обучаем модель на всех признаках, чтобы получить важность\n",
    "model_full = RandomForestRegressor(**rf_params)\n",
    "model_full.fit(X_imputed, y)\n",
    "\n",
    "feature_importances = model_full.feature_importances_\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    'Feature': X_imputed.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Выбираем топ-50 признаков (в вашем примере 11, оставил 11)\n",
    "top_50_features = feat_imp_df.head(11)['Feature'].tolist()\n",
    "print(f\"Используем топ-50 признаков по важности для обучения модели:\")\n",
    "\n",
    "for f in top_50_features:\n",
    "    print(f\"- {f}\")\n",
    "\n",
    "# Отбираем только топ-50 признаков\n",
    "X_top50 = X_imputed[top_50_features]\n",
    "\n",
    "# Кросс-валидация на топ-50 признаках\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "mae_list, mse_list, rmse_list, medae_list, r2_list = [], [], [], [], []\n",
    "\n",
    "print(\"\\nRunning 6-fold cross-validation on top-50 features...\")\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_top50), 1):\n",
    "    X_train_cv, X_val_cv = X_top50.iloc[train_index], X_top50.iloc[val_index]\n",
    "    y_train_cv, y_val_cv = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model_cv = RandomForestRegressor(**rf_params)\n",
    "    model_cv.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    y_pred_cv = model_cv.predict(X_val_cv)\n",
    "\n",
    "    mae_list.append(mean_absolute_error(y_val_cv, y_pred_cv))\n",
    "    mse_list.append(mean_squared_error(y_val_cv, y_pred_cv))\n",
    "    rmse_list.append(np.sqrt(mse_list[-1]))\n",
    "    medae_list.append(median_absolute_error(y_val_cv, y_pred_cv))\n",
    "    r2_list.append(r2_score(y_val_cv, y_pred_cv))\n",
    "\n",
    "    print(f\"Fold {fold} R²: {r2_list[-1]:.4f}\")\n",
    "\n",
    "print(\"\\nCross-validation results (top-50 features):\")\n",
    "print(f\"MAE: {np.mean(mae_list):.4f} ± {np.std(mae_list):.4f}\")\n",
    "print(f\"RMSE: {np.mean(rmse_list):.4f} ± {np.std(rmse_list):.4f}\")\n",
    "print(f\"R²: {np.mean(r2_list):.4f} ± {np.std(r2_list):.4f}\")\n",
    "\n",
    "# Разделение на train/test с топ-50 признаками\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top50, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Обучение модели на train с топ-50 признаками\n",
    "rf_model_eval = RandomForestRegressor(**rf_params)\n",
    "rf_model_eval.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания и оценка на тесте\n",
    "y_pred = rf_model_eval.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nTest set performance (top-50 features):\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MedAE: {medae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "# График остатков\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_pred, y=residuals)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals (Actual - Predicted)')\n",
    "plt.title(f'log(SI): Residuals plot - RandomForest evaluation model (Test set R²={r2:.4f})')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"log(SI)_rf_residuals_plot_top50.png\")\n",
    "plt.close()\n",
    "\n",
    "# Финальная модель на всех данных с топ-50 признаками\n",
    "rf_model_final = RandomForestRegressor(**rf_params)\n",
    "rf_model_final.fit(X_top50, y)\n",
    "\n",
    "feature_importances_final = rf_model_final.feature_importances_\n",
    "feat_imp_df_final = pd.DataFrame({\n",
    "    'Feature': X_top50.columns,\n",
    "    'Importance': feature_importances_final\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 30 важнейших признаков финальной модели:\")\n",
    "print(feat_imp_df_final.head(30))\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "sns.barplot(x='Importance', y='Feature', data=feat_imp_df_final.head(30))\n",
    "plt.title(\"log(SI): Top 30 Feature Importances RandomForest Final Model (top-50 features)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"log(SI)_rf_feature_importance_top30_top50.png\")\n",
    "plt.close()\n",
    "\n",
    "# Сохраняем финальную модель\n",
    "joblib.dump(rf_model_final, 'rf_final_model_SI_top50.pkl')\n",
    "print(\"Финальная модель обучена на топ-50 признаках и сохранена в 'rf_final_model_SI_top50.pkl'\")\n",
    "print(\"Графики сохранены с суффиксом '_top50'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0d61f099-30e5-4e2a-9c8c-b5f0e466147a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Признаки log_IC50 и log_CC50 добавлены в df_bin.\n",
      "Используем топ-50 признаков по важности для обучения модели:\n",
      "- S_2\n",
      "- log_2\n",
      "- log_IC50\n",
      "- log_CC50\n",
      "- VSA_EState8\n",
      "- PEOE_VSA9\n",
      "- FpDensityMorgan3\n",
      "- SlogP_VSA5\n",
      "- EState_VSA3\n",
      "- EState_VSA4\n",
      "- VSA_EState6\n",
      "- EState_VSA7\n",
      "- MinAbsEStateIndex\n",
      "- VSA_EState7\n",
      "- qed\n",
      "- EState_VSA2\n",
      "- VSA_EState3\n",
      "- AvgIpc\n",
      "- PEOE_VSA7\n",
      "- EState_VSA8\n",
      "- BCUT2D_MRLOW\n",
      "- FpDensityMorgan1\n",
      "- VSA_EState1\n",
      "- MolWt_TPSA_ratio\n",
      "\n",
      "Running 6-fold cross-validation on top-50 features...\n",
      "Fold 1 R²: 0.4981\n",
      "Fold 2 R²: 0.5265\n",
      "Fold 3 R²: 0.5857\n",
      "Fold 4 R²: 0.5770\n",
      "Fold 5 R²: 0.6006\n",
      "Fold 6 R²: 0.5462\n",
      "\n",
      "Cross-validation results (top-50 features):\n",
      "MAE: 0.3309 ± 0.0168\n",
      "RMSE: 0.4981 ± 0.0311\n",
      "R²: 0.5557 ± 0.0357\n",
      "\n",
      "Test set performance (top-50 features):\n",
      "MAE: 0.3516\n",
      "MSE: 0.2823\n",
      "RMSE: 0.5313\n",
      "MedAE: 0.2270\n",
      "R²: 0.5286\n",
      "\n",
      "Top 30 важнейших признаков финальной модели:\n",
      "              Feature  Importance\n",
      "1               log_2   31.489676\n",
      "0                 S_2   25.742169\n",
      "2            log_IC50   10.634645\n",
      "3            log_CC50    2.964564\n",
      "4         VSA_EState8    2.695590\n",
      "18          PEOE_VSA7    1.987864\n",
      "21   FpDensityMorgan1    1.892955\n",
      "5           PEOE_VSA9    1.877994\n",
      "6    FpDensityMorgan3    1.761731\n",
      "23   MolWt_TPSA_ratio    1.665172\n",
      "20       BCUT2D_MRLOW    1.568224\n",
      "13        VSA_EState7    1.535795\n",
      "16        VSA_EState3    1.449227\n",
      "19        EState_VSA8    1.424501\n",
      "17             AvgIpc    1.357674\n",
      "7          SlogP_VSA5    1.307156\n",
      "22        VSA_EState1    1.207307\n",
      "14                qed    1.200718\n",
      "9         EState_VSA4    1.142501\n",
      "15        EState_VSA2    1.127625\n",
      "10        VSA_EState6    1.116325\n",
      "12  MinAbsEStateIndex    1.084832\n",
      "8         EState_VSA3    1.013104\n",
      "11        EState_VSA7    0.752651\n",
      "Финальная модель обучена на топ-50 признаках и сохранена в 'catboost_final_model_SI_top50.pkl'\n",
      "Графики сохранены с суффиксом '_top50'.\n",
      "\n",
      "Тест производительности модели CatBoost для различного количества топ-признаков:\n",
      "Iteration top-10 features:\n",
      "MAE: 0.3530\n",
      "R²:  0.5273\n",
      "\n",
      "Iteration top-11 features:\n",
      "MAE: 0.3494\n",
      "R²:  0.5344\n",
      "\n",
      "Iteration top-12 features:\n",
      "MAE: 0.3526\n",
      "R²:  0.5302\n",
      "\n",
      "Iteration top-13 features:\n",
      "MAE: 0.3519\n",
      "R²:  0.5253\n",
      "\n",
      "Iteration top-14 features:\n",
      "MAE: 0.3523\n",
      "R²:  0.5289\n",
      "\n",
      "Iteration top-15 features:\n",
      "MAE: 0.3547\n",
      "R²:  0.5257\n",
      "\n",
      "Iteration top-16 features:\n",
      "MAE: 0.3557\n",
      "R²:  0.5230\n",
      "\n",
      "Iteration top-17 features:\n",
      "MAE: 0.3586\n",
      "R²:  0.5178\n",
      "\n",
      "Iteration top-18 features:\n",
      "MAE: 0.3557\n",
      "R²:  0.5238\n",
      "\n",
      "Iteration top-19 features:\n",
      "MAE: 0.3515\n",
      "R²:  0.5258\n",
      "\n",
      "Iteration top-20 features:\n",
      "MAE: 0.3530\n",
      "R²:  0.5218\n",
      "\n",
      "Iteration top-21 features:\n",
      "MAE: 0.3565\n",
      "R²:  0.5232\n",
      "\n",
      "Iteration top-22 features:\n",
      "MAE: 0.3511\n",
      "R²:  0.5273\n",
      "\n",
      "Iteration top-23 features:\n",
      "MAE: 0.3579\n",
      "R²:  0.5184\n",
      "\n",
      "Iteration top-24 features:\n",
      "MAE: 0.3516\n",
      "R²:  0.5286\n",
      "\n",
      "Iteration top-25 features:\n",
      "MAE: 0.3501\n",
      "R²:  0.5250\n",
      "\n",
      "Iteration top-26 features:\n",
      "MAE: 0.3495\n",
      "R²:  0.5281\n",
      "\n",
      "Iteration top-27 features:\n",
      "MAE: 0.3519\n",
      "R²:  0.5200\n",
      "\n",
      "Iteration top-28 features:\n",
      "MAE: 0.3504\n",
      "R²:  0.5257\n",
      "\n",
      "Iteration top-29 features:\n",
      "MAE: 0.3550\n",
      "R²:  0.5160\n",
      "\n",
      "Iteration top-30 features:\n",
      "MAE: 0.3522\n",
      "R²:  0.5229\n",
      "\n",
      "Iteration top-31 features:\n",
      "MAE: 0.3564\n",
      "R²:  0.5166\n",
      "\n",
      "Iteration top-32 features:\n",
      "MAE: 0.3516\n",
      "R²:  0.5213\n",
      "\n",
      "Iteration top-33 features:\n",
      "MAE: 0.3523\n",
      "R²:  0.5174\n",
      "\n",
      "Iteration top-34 features:\n",
      "MAE: 0.3532\n",
      "R²:  0.5243\n",
      "\n",
      "Iteration top-35 features:\n",
      "MAE: 0.3511\n",
      "R²:  0.5196\n",
      "\n",
      "Iteration top-36 features:\n",
      "MAE: 0.3519\n",
      "R²:  0.5234\n",
      "\n",
      "Iteration top-37 features:\n",
      "MAE: 0.3531\n",
      "R²:  0.5192\n",
      "\n",
      "Iteration top-38 features:\n",
      "MAE: 0.3546\n",
      "R²:  0.5153\n",
      "\n",
      "Iteration top-39 features:\n",
      "MAE: 0.3532\n",
      "R²:  0.5174\n",
      "\n",
      "Iteration top-40 features:\n",
      "MAE: 0.3531\n",
      "R²:  0.5186\n",
      "\n",
      "Iteration top-41 features:\n",
      "MAE: 0.3550\n",
      "R²:  0.5165\n",
      "\n",
      "Iteration top-42 features:\n",
      "MAE: 0.3524\n",
      "R²:  0.5177\n",
      "\n",
      "Iteration top-43 features:\n",
      "MAE: 0.3559\n",
      "R²:  0.5194\n",
      "\n",
      "Iteration top-44 features:\n",
      "MAE: 0.3540\n",
      "R²:  0.5237\n",
      "\n",
      "Iteration top-45 features:\n",
      "MAE: 0.3559\n",
      "R²:  0.5192\n",
      "\n",
      "Iteration top-46 features:\n",
      "MAE: 0.3521\n",
      "R²:  0.5230\n",
      "\n",
      "Iteration top-47 features:\n",
      "MAE: 0.3556\n",
      "R²:  0.5175\n",
      "\n",
      "Iteration top-48 features:\n",
      "MAE: 0.3583\n",
      "R²:  0.5178\n",
      "\n",
      "Iteration top-49 features:\n",
      "MAE: 0.3532\n",
      "R²:  0.5224\n",
      "\n",
      "Iteration top-50 features:\n",
      "MAE: 0.3529\n",
      "R²:  0.5215\n",
      "\n",
      "Iteration top-51 features:\n",
      "MAE: 0.3548\n",
      "R²:  0.5193\n",
      "\n",
      "Iteration top-52 features:\n",
      "MAE: 0.3547\n",
      "R²:  0.5188\n",
      "\n",
      "Iteration top-53 features:\n",
      "MAE: 0.3554\n",
      "R²:  0.5197\n",
      "\n",
      "Iteration top-54 features:\n",
      "MAE: 0.3582\n",
      "R²:  0.5119\n",
      "\n",
      "Iteration top-55 features:\n",
      "MAE: 0.3569\n",
      "R²:  0.5121\n",
      "\n",
      "Iteration top-56 features:\n",
      "MAE: 0.3535\n",
      "R²:  0.5183\n",
      "\n",
      "Iteration top-57 features:\n",
      "MAE: 0.3576\n",
      "R²:  0.5105\n",
      "\n",
      "Iteration top-58 features:\n",
      "MAE: 0.3532\n",
      "R²:  0.5163\n",
      "\n",
      "Iteration top-59 features:\n",
      "MAE: 0.3586\n",
      "R²:  0.5123\n",
      "\n",
      "Iteration top-60 features:\n",
      "MAE: 0.3563\n",
      "R²:  0.5155\n",
      "\n",
      "Iteration top-61 features:\n",
      "MAE: 0.3576\n",
      "R²:  0.5135\n",
      "\n",
      "Iteration top-62 features:\n",
      "MAE: 0.3567\n",
      "R²:  0.5136\n",
      "\n",
      "Iteration top-63 features:\n",
      "MAE: 0.3540\n",
      "R²:  0.5162\n",
      "\n",
      "Iteration top-64 features:\n",
      "MAE: 0.3581\n",
      "R²:  0.5139\n",
      "\n",
      "Iteration top-65 features:\n",
      "MAE: 0.3554\n",
      "R²:  0.5121\n",
      "\n",
      "Iteration top-66 features:\n",
      "MAE: 0.3559\n",
      "R²:  0.5149\n",
      "\n",
      "Iteration top-67 features:\n",
      "MAE: 0.3572\n",
      "R²:  0.5142\n",
      "\n",
      "Iteration top-68 features:\n",
      "MAE: 0.3572\n",
      "R²:  0.5095\n",
      "\n",
      "Iteration top-69 features:\n",
      "MAE: 0.3567\n",
      "R²:  0.5136\n",
      "\n",
      "Iteration top-70 features:\n",
      "MAE: 0.3547\n",
      "R²:  0.5121\n",
      "\n",
      "Iteration top-71 features:\n",
      "MAE: 0.3593\n",
      "R²:  0.5083\n",
      "\n",
      "Iteration top-72 features:\n",
      "MAE: 0.3578\n",
      "R²:  0.5101\n",
      "\n",
      "Iteration top-73 features:\n",
      "MAE: 0.3568\n",
      "R²:  0.5117\n",
      "\n",
      "Iteration top-74 features:\n",
      "MAE: 0.3578\n",
      "R²:  0.5117\n",
      "\n",
      "Iteration top-75 features:\n",
      "MAE: 0.3560\n",
      "R²:  0.5090\n",
      "\n",
      "Iteration top-76 features:\n",
      "MAE: 0.3533\n",
      "R²:  0.5146\n",
      "\n",
      "Iteration top-77 features:\n",
      "MAE: 0.3571\n",
      "R²:  0.5125\n",
      "\n",
      "Iteration top-78 features:\n",
      "MAE: 0.3592\n",
      "R²:  0.5110\n",
      "\n",
      "Iteration top-79 features:\n",
      "MAE: 0.3579\n",
      "R²:  0.5103\n",
      "\n",
      "Iteration top-80 features:\n",
      "MAE: 0.3566\n",
      "R²:  0.5107\n",
      "\n",
      "Iteration top-81 features:\n",
      "MAE: 0.3564\n",
      "R²:  0.5122\n",
      "\n",
      "Iteration top-82 features:\n",
      "MAE: 0.3607\n",
      "R²:  0.5058\n",
      "\n",
      "Iteration top-83 features:\n",
      "MAE: 0.3579\n",
      "R²:  0.5078\n",
      "\n",
      "Iteration top-84 features:\n",
      "MAE: 0.3548\n",
      "R²:  0.5150\n",
      "\n",
      "Iteration top-85 features:\n",
      "MAE: 0.3571\n",
      "R²:  0.5099\n",
      "\n",
      "Iteration top-86 features:\n",
      "MAE: 0.3566\n",
      "R²:  0.5112\n",
      "\n",
      "Iteration top-87 features:\n",
      "MAE: 0.3588\n",
      "R²:  0.5081\n",
      "\n",
      "Iteration top-88 features:\n",
      "MAE: 0.3582\n",
      "R²:  0.5086\n",
      "\n",
      "Iteration top-89 features:\n",
      "MAE: 0.3601\n",
      "R²:  0.5089\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import joblib\n",
    "\n",
    "# === Подготовка данных ===\n",
    "# df_bin уже должен быть загружен\n",
    "\n",
    "# === Добавление признаков log_IC50, log_CC50 и расчет log_2, S_2 ===\n",
    "ic50_model = joblib.load('regression_IC50_catboost_final_model_bin.pkl')\n",
    "cc50_model = joblib.load('regression_CC50_lightgbm_final_model_bin.pkl')\n",
    "\n",
    "def add_predicted_feature(df, model, drop_cols=None, imputer_strategy='most_frequent'):\n",
    "    df_tmp = df.copy()\n",
    "    df_tmp.columns = df_tmp.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "    df_tmp.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    if drop_cols:\n",
    "        for c in drop_cols:\n",
    "            if c in df_tmp.columns:\n",
    "                df_tmp.drop(columns=[c], inplace=True)\n",
    "    imputer = SimpleImputer(strategy=imputer_strategy)\n",
    "    X_imputed = pd.DataFrame(imputer.fit_transform(df_tmp), columns=df_tmp.columns)\n",
    "    preds = model.predict(X_imputed)\n",
    "    return preds\n",
    "\n",
    "df_bin['log_IC50'] = add_predicted_feature(df_bin, ic50_model, drop_cols=['log_IC50'])\n",
    "df_bin['log_CC50'] = add_predicted_feature(df_bin, cc50_model, drop_cols=['log_IC50', 'log_CC50', 'log_SI'])\n",
    "df_bin['log_2'] = df_bin['log_IC50'] - df_bin['log_CC50']\n",
    "df_bin['S_2'] = 10**df_bin['log_2']\n",
    "\n",
    "print(\"Признаки log_IC50 и log_CC50 добавлены в df_bin.\")\n",
    "\n",
    "# === Подготовка датасета для log_SI ===\n",
    "df_copy = df_bin.copy()\n",
    "df_copy.columns = df_copy.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "df_copy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "if 'Unnamed_0' in df_copy.columns:\n",
    "    df_copy.drop(columns=['Unnamed_0'], inplace=True)\n",
    "\n",
    "X = df_copy.drop(columns=['log_SI'])\n",
    "y = df_copy['log_SI']\n",
    "\n",
    "# Импутация\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Параметры CatBoost\n",
    "catboost_params = {\n",
    "    'bagging_temperature': 0.13,\n",
    "    'depth': 5,\n",
    "    'iterations': 626,\n",
    "    'l2_leaf_reg': 4.2,\n",
    "    'learning_rate': 0.04,\n",
    "    'verbose': 0,\n",
    "    'random_state': 42,\n",
    "    'loss_function': 'RMSE'\n",
    "}\n",
    "\n",
    "# Обучаем модель на всех признаках, чтобы получить важность\n",
    "model_full = CatBoostRegressor(**catboost_params)\n",
    "model_full.fit(X_imputed, y)\n",
    "\n",
    "feature_importances = model_full.get_feature_importance(Pool(X_imputed, label=y))\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    'Feature': X_imputed.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Выбираем топ-50 признаков\n",
    "top_50_features = feat_imp_df.head(24)['Feature'].tolist()\n",
    "print(f\"Используем топ-50 признаков по важности для обучения модели:\")\n",
    "\n",
    "for f in top_50_features:\n",
    "    print(f\"- {f}\")\n",
    "\n",
    "# Отбираем только топ-50 признаков\n",
    "X_top50 = X_imputed[top_50_features]\n",
    "\n",
    "# Кросс-валидация на топ-50 признаках\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "mae_list, mse_list, rmse_list, medae_list, r2_list = [], [], [], [], []\n",
    "\n",
    "print(\"\\nRunning 6-fold cross-validation on top-50 features...\")\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_top50), 1):\n",
    "    X_train_cv, X_val_cv = X_top50.iloc[train_index], X_top50.iloc[val_index]\n",
    "    y_train_cv, y_val_cv = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model_cv = CatBoostRegressor(**catboost_params)\n",
    "    model_cv.fit(X_train_cv, y_train_cv, verbose=0)\n",
    "\n",
    "    y_pred_cv = model_cv.predict(X_val_cv)\n",
    "\n",
    "    mae_list.append(mean_absolute_error(y_val_cv, y_pred_cv))\n",
    "    mse_list.append(mean_squared_error(y_val_cv, y_pred_cv))\n",
    "    rmse_list.append(np.sqrt(mse_list[-1]))\n",
    "    medae_list.append(median_absolute_error(y_val_cv, y_pred_cv))\n",
    "    r2_list.append(r2_score(y_val_cv, y_pred_cv))\n",
    "\n",
    "    print(f\"Fold {fold} R²: {r2_list[-1]:.4f}\")\n",
    "\n",
    "print(\"\\nCross-validation results (top-50 features):\")\n",
    "print(f\"MAE: {np.mean(mae_list):.4f} ± {np.std(mae_list):.4f}\")\n",
    "print(f\"RMSE: {np.mean(rmse_list):.4f} ± {np.std(rmse_list):.4f}\")\n",
    "print(f\"R²: {np.mean(r2_list):.4f} ± {np.std(r2_list):.4f}\")\n",
    "\n",
    "# Разделение на train/test с топ-50 признаками\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top50, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Обучение модели на train с топ-50 признаками\n",
    "cat_model_eval = CatBoostRegressor(**catboost_params)\n",
    "cat_model_eval.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания и оценка на тесте\n",
    "y_pred = cat_model_eval.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nTest set performance (top-50 features):\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MedAE: {medae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "# График остатков\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_pred, y=residuals)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals (Actual - Predicted)')\n",
    "plt.title(f'log(SI): Residuals plot - CatBoost evaluation model (Test set R²={r2:.4f})')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"log(SI)_catboost_residuals_plot_top50.png\")\n",
    "plt.close()\n",
    "\n",
    "# Финальная модель на всех данных с топ-50 признаками\n",
    "cat_model_final = CatBoostRegressor(**catboost_params)\n",
    "cat_model_final.fit(X_top50, y)\n",
    "\n",
    "feature_importances_final = cat_model_final.get_feature_importance(Pool(X_top50, label=y))\n",
    "feat_imp_df_final = pd.DataFrame({\n",
    "    'Feature': X_top50.columns,\n",
    "    'Importance': feature_importances_final\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 30 важнейших признаков финальной модели:\")\n",
    "print(feat_imp_df_final.head(30))\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "sns.barplot(x='Importance', y='Feature', data=feat_imp_df_final.head(30))\n",
    "plt.title(\"log(SI): Top 30 Feature Importances CatBoost Final Model (top-50 features)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"log(SI)_catboost_feature_importance_top30_top50.png\")\n",
    "plt.close()\n",
    "\n",
    "# Сохраняем финальную модель\n",
    "joblib.dump(cat_model_final, 'catboost_final_model_SI_top50.pkl')\n",
    "print(\"Финальная модель обучена на топ-50 признаках и сохранена в 'catboost_final_model_SI_top50.pkl'\")\n",
    "print(\"Графики сохранены с суффиксом '_top50'.\")\n",
    "\n",
    "# === ДОПОЛНИТЕЛЬНО: Тест модели на top-10 до top-50 признаках ===\n",
    "print(\"\\nТест производительности модели CatBoost для различного количества топ-признаков:\")\n",
    "\n",
    "for n_feats in range(10, 90):\n",
    "    top_features_n = feat_imp_df.head(n_feats)['Feature'].tolist()\n",
    "    X_top_n = X_imputed[top_features_n]\n",
    "\n",
    "    X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(X_top_n, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    model_n = CatBoostRegressor(**catboost_params)\n",
    "    model_n.fit(X_train_n, y_train_n, verbose=0)\n",
    "\n",
    "    y_pred_n = model_n.predict(X_test_n)\n",
    "\n",
    "    mae_n = mean_absolute_error(y_test_n, y_pred_n)\n",
    "    r2_n = r2_score(y_test_n, y_pred_n)\n",
    "\n",
    "    print(f\"Iteration top-{n_feats} features:\")\n",
    "    print(f\"MAE: {mae_n:.4f}\")\n",
    "    print(f\"R²:  {r2_n:.4f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "98af529b-cd54-48f4-a42e-89cbdc1c4b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Признак log_IC50 добавлен в df_bin с использованием модели regression_IC50_catboost_final_model_bin.pkl\n",
      "Running 6-fold cross-validation...\n",
      "Fold 1 R²: 0.3427\n",
      "Fold 2 R²: 0.3294\n",
      "Fold 3 R²: 0.3465\n",
      "Fold 4 R²: 0.3662\n",
      "Fold 5 R²: 0.3686\n",
      "Fold 6 R²: 0.3692\n",
      "\n",
      "Cross-validation results:\n",
      "MAE: 0.4338 ± 0.0206\n",
      "RMSE: 0.6009 ± 0.0261\n",
      "R²: 0.3538 ± 0.0152\n",
      "\n",
      "Test set performance:\n",
      "MAE: 0.4442\n",
      "MSE: 0.3863\n",
      "RMSE: 0.6216\n",
      "MedAE: 0.2953\n",
      "R²: 0.3548\n",
      "\n",
      "Top 30 важнейших признаков:\n",
      "log_IC50: 31.7864\n",
      "VSA_EState8: 1.4716\n",
      "BCUT2D_CHGLO: 1.3318\n",
      "BCUT2D_MRHI: 1.2749\n",
      "EState_VSA3: 1.2582\n",
      "AvgIpc: 1.1778\n",
      "FractionCSP3: 1.1684\n",
      "RingCount: 1.1412\n",
      "EState_VSA4: 1.1349\n",
      "SMR_VSA10: 1.0929\n",
      "FpDensityMorgan3: 1.0885\n",
      "PEOE_VSA8: 1.0710\n",
      "VSA_EState2: 1.0416\n",
      "VSA_EState3: 0.9894\n",
      "FpDensityMorgan2: 0.9701\n",
      "PEOE_VSA6: 0.9619\n",
      "PEOE_VSA_std: 0.9594\n",
      "qed: 0.9165\n",
      "VSA_EState4: 0.8782\n",
      "MaxAbsPartialCharge: 0.8606\n",
      "EState_VSA5: 0.8482\n",
      "EState_VSA8: 0.8303\n",
      "Log_MolWt_TPSA_ratio: 0.8100\n",
      "BCUT2D_MWLOW_log: 0.7929\n",
      "MolLogP: 0.7840\n",
      "SlogP_VSA4: 0.7559\n",
      "SlogP_VSA2: 0.7252\n",
      "PEOE_VSA_max: 0.7237\n",
      "CSP3_Kappa1_ratio: 0.7197\n",
      "BCUT2D_LOGPHI: 0.7175\n",
      "Финальная модель обучена на всех данных и сохранена в 'catboost_final_model_SI.pkl'\n",
      "Графики сохранены в 'log(SI) catboost_residuals_plot.png' и 'log(SI) catboost_feature_importance_top30.png'\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import joblib\n",
    "\n",
    "# === Добавление признака log_IC50 на основе ранее обученной модели ===\n",
    "\n",
    "# Загрузка модели IC50\n",
    "ic50_model = joblib.load('regression_IC50_catboost_final_model_bin.pkl')\n",
    "\n",
    "# Подготовка данных для предсказания log_IC50\n",
    "X_ic50 = df_bin.copy()\n",
    "X_ic50.columns = X_ic50.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "X_ic50.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Удаление log_IC50, если он уже есть\n",
    "if 'log_IC50' in X_ic50.columns:\n",
    "    X_ic50 = X_ic50.drop(columns=['log_IC50'])\n",
    "\n",
    "# Импутация пропусков (most_frequent, как в обучении модели)\n",
    "ic50_imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_ic50_imputed = pd.DataFrame(ic50_imputer.fit_transform(X_ic50), columns=X_ic50.columns)\n",
    "\n",
    "# Предсказание и добавление признака\n",
    "df_bin['log_IC50'] = ic50_model.predict(X_ic50_imputed)\n",
    "print(\"Признак log_IC50 добавлен в df_bin с использованием модели regression_IC50_catboost_final_model_bin.pkl\")\n",
    "\n",
    "# === Обучение модели для log_SI ===\n",
    "\n",
    "# Копируем и чистим данные\n",
    "df_copy = df_bin.copy()\n",
    "df_copy.columns = df_copy.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "df_copy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "if 'Unnamed_0' in df_copy.columns:\n",
    "    df_copy.drop(columns=['Unnamed_0'], inplace=True)\n",
    "\n",
    "X = df_copy.drop(columns=['log_SI'])\n",
    "y = df_copy['log_SI']\n",
    "\n",
    "# Импутация\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Параметры CatBoost\n",
    "catboost_params = {\n",
    "    'bagging_temperature': 0.13,\n",
    "    'depth': 5,\n",
    "    'iterations': 626,\n",
    "    'l2_leaf_reg': 4.2,\n",
    "    'learning_rate': 0.04,\n",
    "    'verbose': 0,\n",
    "    'random_state': 42,\n",
    "    'loss_function': 'RMSE'\n",
    "}\n",
    "\n",
    "# Кросс-валидация\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "mae_list, mse_list, rmse_list, medae_list, r2_list = [], [], [], [], []\n",
    "\n",
    "print(\"Running 6-fold cross-validation...\")\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_imputed), 1):\n",
    "    X_train_cv, X_val_cv = X_imputed.iloc[train_index], X_imputed.iloc[val_index]\n",
    "    y_train_cv, y_val_cv = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model_cv = CatBoostRegressor(**catboost_params)\n",
    "    model_cv.fit(X_train_cv, y_train_cv, verbose=0)\n",
    "\n",
    "    y_pred_cv = model_cv.predict(X_val_cv)\n",
    "\n",
    "    mae_list.append(mean_absolute_error(y_val_cv, y_pred_cv))\n",
    "    mse_list.append(mean_squared_error(y_val_cv, y_pred_cv))\n",
    "    rmse_list.append(np.sqrt(mse_list[-1]))\n",
    "    medae_list.append(median_absolute_error(y_val_cv, y_pred_cv))\n",
    "    r2_list.append(r2_score(y_val_cv, y_pred_cv))\n",
    "\n",
    "    print(f\"Fold {fold} R²: {r2_list[-1]:.4f}\")\n",
    "\n",
    "print(\"\\nCross-validation results:\")\n",
    "print(f\"MAE: {np.mean(mae_list):.4f} ± {np.std(mae_list):.4f}\")\n",
    "print(f\"RMSE: {np.mean(rmse_list):.4f} ± {np.std(rmse_list):.4f}\")\n",
    "print(f\"R²: {np.mean(r2_list):.4f} ± {np.std(r2_list):.4f}\")\n",
    "\n",
    "# Оценка на отложенной выборке\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.25, random_state=42)\n",
    "\n",
    "cat_model_eval = CatBoostRegressor(**catboost_params)\n",
    "cat_model_eval.fit(X_train, y_train)\n",
    "\n",
    "y_pred = cat_model_eval.predict(X_test)\n",
    "\n",
    "# Метрики\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nTest set performance:\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MedAE: {medae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "# График остатков\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_pred, y=residuals)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals (Actual - Predicted)')\n",
    "plt.title(f'log(SI): Residuals plot - CatBoost evaluation model (Test set R²={r2:.4f})')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"log(SI) catboost_residuals_plot.png\")\n",
    "plt.close()\n",
    "\n",
    "# Важность признаков\n",
    "cat_model_final = CatBoostRegressor(**catboost_params)\n",
    "cat_model_final.fit(X_imputed, y)\n",
    "\n",
    "feature_importances = cat_model_final.get_feature_importance(Pool(X_imputed, label=y))\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    'Feature': X_imputed.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 30 важнейших признаков:\")\n",
    "for i, row in feat_imp_df.head(30).iterrows():\n",
    "    print(f\"{row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "sns.barplot(x='Importance', y='Feature', data=feat_imp_df.head(30))\n",
    "plt.title(\"log(SI): Top 30 Feature Importances CatBoost Final Model\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"log(SI) catboost_feature_importance_top30.png\")\n",
    "plt.close()\n",
    "\n",
    "# Сохранение модели\n",
    "joblib.dump(cat_model_final, 'catboost_final_model_SI.pkl')\n",
    "print(\"Финальная модель обучена на всех данных и сохранена в 'catboost_final_model_SI.pkl'\")\n",
    "print(\"Графики сохранены в 'log(SI) catboost_residuals_plot.png' и 'log(SI) catboost_feature_importance_top30.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dd1d1527-c02d-42af-9fff-87e7b217eb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 6-fold cross-validation...\n",
      "Fold 1 R²: 0.2570\n",
      "Fold 2 R²: 0.2114\n",
      "Fold 3 R²: 0.2350\n",
      "Fold 4 R²: 0.2382\n",
      "Fold 5 R²: 0.2589\n",
      "Fold 6 R²: 0.3044\n",
      "\n",
      "Cross-validation results:\n",
      "MAE: 0.4832 ± 0.0257\n",
      "RMSE: 0.6471 ± 0.0331\n",
      "R²: 0.2508 ± 0.0287\n",
      "\n",
      "Test set performance:\n",
      "MAE: 0.5004\n",
      "MSE: 0.4468\n",
      "RMSE: 0.6685\n",
      "MedAE: 0.3724\n",
      "R²: 0.2538\n",
      "\n",
      "Top 30 важнейших признаков:\n",
      "FractionCSP3: 3.8738\n",
      "VSA_EState8: 3.0103\n",
      "BCUT2D_CHGLO: 2.7643\n",
      "VSA_EState6: 2.4517\n",
      "VSA_EState4: 2.2712\n",
      "BCUT2D_MRLOW: 2.2073\n",
      "RingCount: 2.1850\n",
      "SlogP_VSA5: 1.9432\n",
      "FpDensityMorgan3: 1.9268\n",
      "Log_Flexibility: 1.8815\n",
      "qed: 1.8293\n",
      "AvgIpc: 1.7758\n",
      "EState_VSA4: 1.6430\n",
      "VSA_EState2: 1.6094\n",
      "NumSaturatedHeterocycles: 1.5524\n",
      "HallKierAlpha: 1.4643\n",
      "SMR_VSA4: 1.4329\n",
      "NHOHCount: 1.4261\n",
      "MinPartialCharge: 1.3925\n",
      "NumSaturatedCarbocycles: 1.3219\n",
      "Flexibility: 1.2937\n",
      "MaxAbsPartialCharge: 1.1816\n",
      "EState_VSA_std: 1.1403\n",
      "PEOE_VSA7: 1.0894\n",
      "CSP3_Kappa1_ratio: 1.0805\n",
      "MinAbsEStateIndex: 1.0672\n",
      "EState_VSA5: 0.9769\n",
      "VSA_EState3: 0.9737\n",
      "PEOE_VSA2: 0.9709\n",
      "EState_VSA3: 0.9530\n",
      "Финальная модель обучена на всех данных и сохранена в 'catboost_final_model_SI.pkl'\n",
      "Графики сохранены в 'log(SI) catboost_residuals_plot.png' и 'catboost_feature_importance_top30.png'\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import joblib\n",
    "\n",
    "# Копируем данные, чистим\n",
    "df_copy = df_bin.copy()\n",
    "df_copy.columns = df_copy.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "df_copy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "if 'Unnamed_0' in df_copy.columns:\n",
    "    df_copy.drop(columns=['Unnamed_0'], inplace=True)\n",
    "\n",
    "X = df_copy.drop(columns=['log_SI'])\n",
    "y = df_copy['log_SI']\n",
    "\n",
    "# Импутация\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "catboost_params = {\n",
    "    'bagging_temperature': 0.13,\n",
    "    'depth': 5,\n",
    "    'iterations': 626,\n",
    "    'l2_leaf_reg': 4.2,\n",
    "    'learning_rate': 0.04,\n",
    "    'verbose': 0,\n",
    "    'random_state': 42,\n",
    "    'loss_function': 'RMSE'\n",
    "}\n",
    "\n",
    "# Кросс-валидация\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "mae_list, mse_list, rmse_list, medae_list, r2_list = [], [], [], [], []\n",
    "\n",
    "print(\"Running 6-fold cross-validation...\")\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_imputed), 1):\n",
    "    X_train_cv, X_val_cv = X_imputed.iloc[train_index], X_imputed.iloc[val_index]\n",
    "    y_train_cv, y_val_cv = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    model_cv = CatBoostRegressor(**catboost_params)\n",
    "    model_cv.fit(X_train_cv, y_train_cv, verbose=0)\n",
    "\n",
    "    y_pred_cv = model_cv.predict(X_val_cv)\n",
    "\n",
    "    mae_list.append(mean_absolute_error(y_val_cv, y_pred_cv))\n",
    "    mse_list.append(mean_squared_error(y_val_cv, y_pred_cv))\n",
    "    rmse_list.append(np.sqrt(mse_list[-1]))\n",
    "    medae_list.append(median_absolute_error(y_val_cv, y_pred_cv))\n",
    "    r2_list.append(r2_score(y_val_cv, y_pred_cv))\n",
    "\n",
    "    print(f\"Fold {fold} R²: {r2_list[-1]:.4f}\")\n",
    "\n",
    "print(\"\\nCross-validation results:\")\n",
    "print(f\"MAE: {np.mean(mae_list):.4f} ± {np.std(mae_list):.4f}\")\n",
    "print(f\"RMSE: {np.mean(rmse_list):.4f} ± {np.std(rmse_list):.4f}\")\n",
    "print(f\"R²: {np.mean(r2_list):.4f} ± {np.std(r2_list):.4f}\")\n",
    "\n",
    "# Оценка на отложенной выборке\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.25, random_state=42)\n",
    "\n",
    "cat_model_eval = CatBoostRegressor(**catboost_params)\n",
    "cat_model_eval.fit(X_train, y_train)\n",
    "\n",
    "y_pred = cat_model_eval.predict(X_test)\n",
    "\n",
    "# Метрики\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nTest set performance:\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MedAE: {medae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "# График остатков\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_pred, y=residuals)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals (Actual - Predicted)')\n",
    "plt.title(f'log(SI): Residuals plot - CatBoost evaluation model (Test set R²={r2:.4f})')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"log(SI) catboost_residuals_plot.png\")\n",
    "plt.close()\n",
    "\n",
    "# Важность признаков\n",
    "cat_model_final = CatBoostRegressor(**catboost_params)\n",
    "cat_model_final.fit(X_imputed, y)\n",
    "\n",
    "feature_importances = cat_model_final.get_feature_importance(Pool(X_imputed, label=y))\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    'Feature': X_imputed.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 30 важнейших признаков:\")\n",
    "for i, row in feat_imp_df.head(30).iterrows():\n",
    "    print(f\"{row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "sns.barplot(x='Importance', y='Feature', data=feat_imp_df.head(30))\n",
    "plt.title(\"log(SI): Top 30 Feature Importances CatBoost Final Model\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"log(SI) catboost_feature_importance_top30.png\")\n",
    "plt.close()\n",
    "\n",
    "# Сохранение модели\n",
    "joblib.dump(cat_model_final, 'catboost_final_model_SI.pkl')\n",
    "print(\"Финальная модель обучена на всех данных и сохранена в 'catboost_final_model_SI.pkl'\")\n",
    "print(\"Графики сохранены в 'log(SI) catboost_residuals_plot.png' и 'catboost_feature_importance_top30.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "664825c6-46e9-45ac-9ab4-10532bdbb325",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 53\u001b[0m\n\u001b[0;32m     42\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     43\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     44\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m     return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     50\u001b[0m )\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Обучение\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# 5. Результаты\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЛучшие параметры:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# 1. Подготовка данных\n",
    "X = df.drop(columns=['log_SI'])\n",
    "y = df['log_SI']\n",
    "\n",
    "# Импутация пропусков\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Делим на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imputed, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Настройка модели и параметров\n",
    "model = CatBoostRegressor(verbose=0, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'depth': [4, 5, 6],\n",
    "    'learning_rate': [0.03, 0.05, 0.08],\n",
    "    'iterations': [300, 400],\n",
    "    'l2_leaf_reg': [2, 3, 4],\n",
    "    'bagging_temperature': [0, 1]\n",
    "}\n",
    "\n",
    "# 3. Метрики\n",
    "scoring = {\n",
    "    'rmse': make_scorer(mean_squared_error, greater_is_better=False),\n",
    "    'r2': make_scorer(r2_score)\n",
    "}\n",
    "\n",
    "# 4. GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='r2',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Обучение\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 5. Результаты\n",
    "print(\"Лучшие параметры:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Оценка на тестовой выборке\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "rmse_test = mean_squared_error(y_test, y_pred)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке:\")\n",
    "print(f\"RMSE: {rmse_test:.4f}\")\n",
    "print(f\"R²:   {r2_test:.4f}\")\n",
    "\n",
    "# 6. Графики по результатам GridSearchCV\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Вычисляем RMSE (отрицательный MSE → RMSE)\n",
    "cv_results['rmse'] = (-cv_results['mean_test_rmse'])**0.5\n",
    "cv_results_sorted_rmse = cv_results.sort_values(by='rmse', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# График RMSE\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(data=cv_results_sorted_rmse['rmse'], marker='o')\n",
    "plt.title('RMSE по комбинациям параметров (от худших к лучшим)')\n",
    "plt.xlabel('Комбинация параметров (индекс)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# График R²\n",
    "cv_results_sorted_r2 = cv_results.sort_values(by='mean_test_r2', ascending=True).reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(data=cv_results_sorted_r2['mean_test_r2'], marker='o')\n",
    "plt.title('R² по комбинациям параметров (от худших к лучшим)')\n",
    "plt.xlabel('Комбинация параметров (индекс)')\n",
    "plt.ylabel('R²')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f19b07e9-3e36-4064-b390-400304cd6b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка датасетов:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 Загружаем df.csv\n",
      "🧹 Удаляем признаки с утечкой: FpDensityMorgan2, SI, FpDensityMorgan3, IC50, mM, CC50, mM, log_IC50, FpDensityMorgan1, log_CC50\n",
      "⚙️ Препроцессинг...\n",
      " Обучаем модель...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка датасетов:   0%|          | 0/4 [01:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Обучение завершено. Итераций: 58\n",
      " Кросс-валидация...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка датасетов:  25%|██▌       | 1/4 [04:28<13:24, 268.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " df.csv готово: R² = 0.2008, MAE = 0.5131\n",
      "\n",
      "\n",
      "📂 Загружаем df_bin.csv\n",
      "🧹 Удаляем признаки с утечкой: FpDensityMorgan2, SI, FpDensityMorgan3, IC50, mM, CC50, mM, log_IC50, FpDensityMorgan1, log_CC50\n",
      "⚙️ Препроцессинг...\n",
      " Обучаем модель...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка датасетов:  25%|██▌       | 1/4 [05:19<13:24, 268.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Обучение завершено. Итераций: 49\n",
      " Кросс-валидация...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка датасетов:  50%|█████     | 2/4 [08:41<08:39, 259.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " df_bin.csv готово: R² = 0.1903, MAE = 0.5108\n",
      "\n",
      "\n",
      "📂 Загружаем df_cut.csv\n",
      "🧹 Удаляем признаки с утечкой: SI, IC50, mM, CC50, mM, log_IC50, FpDensityMorgan1, log_CC50\n",
      "⚙️ Препроцессинг...\n",
      " Обучаем модель...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка датасетов:  50%|█████     | 2/4 [09:30<08:39, 259.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Обучение завершено. Итераций: 50\n",
      " Кросс-валидация...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка датасетов:  75%|███████▌  | 3/4 [13:36<04:35, 275.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " df_cut.csv готово: R² = 0.1933, MAE = 0.5112\n",
      "\n",
      "\n",
      "📂 Загружаем df_cut_bin.csv\n",
      "🧹 Удаляем признаки с утечкой: SI, IC50, mM, CC50, mM, log_IC50, FpDensityMorgan1, log_CC50\n",
      "⚙️ Препроцессинг...\n",
      " Обучаем модель...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка датасетов:  75%|███████▌  | 3/4 [14:23<04:35, 275.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Обучение завершено. Итераций: 47\n",
      " Кросс-валидация...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка датасетов: 100%|██████████| 4/4 [17:30<00:00, 262.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " df_cut_bin.csv готово: R² = 0.1976, MAE = 0.5087\n",
      "\n",
      "\n",
      " === Сравнение результатов по датасетам ===\n",
      "       Dataset  Test MAE  Test RMSE  Test R²  CV R² Mean  CV R² Std\n",
      "        df.csv    0.5131     0.6983   0.2008      0.2241     0.0638\n",
      "    df_bin.csv    0.5108     0.6915   0.1903      0.2027     0.0675\n",
      "    df_cut.csv    0.5112     0.7015   0.1933      0.1922     0.0499\n",
      "df_cut_bin.csv    0.5087     0.6884   0.1976      0.2196     0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# === Настройки модели ===\n",
    "mlp = MLPRegressor(\n",
    "    hidden_layer_sizes=(1024, 512, 256, 128, 64, 32, 16),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0005,\n",
    "    batch_size=32,\n",
    "    learning_rate='adaptive',\n",
    "    learning_rate_init=0.0003,\n",
    "    max_iter=3000,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=40,\n",
    "    random_state=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# === Пути к датасетам ===\n",
    "datasets = {\n",
    "    \"df.csv\": \"df.csv\",\n",
    "    \"df_bin.csv\": \"df_bin.csv\",\n",
    "    \"df_cut.csv\": \"df_cut.csv\",\n",
    "    \"df_cut_bin.csv\": \"df_cut_bin.csv\"\n",
    "}\n",
    "\n",
    "# === Целевая переменная ===\n",
    "target = \"log_SI\"\n",
    "\n",
    "# === Результаты по каждому датасету ===\n",
    "results = []\n",
    "\n",
    "# tqdm для отображения прогресса\n",
    "for name in tqdm(datasets, desc=\"Обработка датасетов\"):\n",
    "    path = datasets[name]\n",
    "    tqdm.write(f\"\\n📂 Загружаем {name}\")\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    if target not in df.columns:\n",
    "        tqdm.write(f\"⚠️ Целевая переменная '{target}' не найдена в {name}, пропускаем.\")\n",
    "        continue\n",
    "\n",
    "    # Удалим признаки, содержащие утечку\n",
    "    leak_keywords = ['IC50', 'CC50', 'SI']\n",
    "    leak_cols = [col for col in df.columns if any(key.lower() in col.lower() for key in leak_keywords)]\n",
    "    leak_cols = list(set(leak_cols) - set([target]))  # Не удаляем целевую переменную\n",
    "\n",
    "    if leak_cols:\n",
    "        tqdm.write(f\"🧹 Удаляем признаки с утечкой: {', '.join(leak_cols)}\")\n",
    "\n",
    "    # Отделяем признаки и целевую переменную\n",
    "    X = df.drop(columns=[target] + leak_cols)\n",
    "    y = df[target]\n",
    "\n",
    "    # Очистка и препроцессинг\n",
    "    tqdm.write(\"⚙️ Препроцессинг...\")\n",
    "    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed), columns=X.columns)\n",
    "\n",
    "    # Разделение на train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Обучение модели\n",
    "    tqdm.write(\" Обучаем модель...\")\n",
    "    model = MLPRegressor(**mlp.get_params())\n",
    "    model.fit(X_train, y_train)\n",
    "    tqdm.write(f\" Обучение завершено. Итераций: {model.n_iter_}\")\n",
    "\n",
    "    # Предсказания и метрики\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Кросс-валидация\n",
    "    tqdm.write(\" Кросс-валидация...\")\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_scaled, y, cv=kf, scoring='r2', n_jobs=-1)\n",
    "\n",
    "    # Сохраняем метрики\n",
    "    results.append({\n",
    "        \"Dataset\": name,\n",
    "        \"Test MAE\": mae,\n",
    "        \"Test RMSE\": rmse,\n",
    "        \"Test R²\": r2,\n",
    "        \"CV R² Mean\": cv_scores.mean(),\n",
    "        \"CV R² Std\": cv_scores.std()\n",
    "    })\n",
    "\n",
    "    tqdm.write(f\" {name} готово: R² = {r2:.4f}, MAE = {mae:.4f}\\n\")\n",
    "\n",
    "# === Вывод таблицы результатов ===\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n === Сравнение результатов по датасетам ===\", flush=True)\n",
    "print(results_df.to_string(index=False, float_format=\"%.4f\"), flush=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
